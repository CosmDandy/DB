{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Данные"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Подготовка данных для таблицы book"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "directory = Path(\"input/book\")\n",
    "book = pd.concat([pd.read_csv(f).drop(\n",
    "    ['RatingDist1', 'RatingDist4', 'RatingDistTotal', 'RatingDist2', 'RatingDist5', 'RatingDist3', 'Id'], axis=1) for f\n",
    "    in directory.glob(\"*.csv\")], ignore_index=True)\n",
    "\n",
    "# book = book.drop(['pagesNumber', 'Count of text reviews'], axis=1)\n",
    "book.Language = book.Language.fillna('eng')\n",
    "book.pagesNumber = book.pagesNumber.fillna(random.randint(250, 1500))\n",
    "book.pagesNumber = book.pagesNumber.astype('int')\n",
    "book.Publisher = book.Publisher.fillna('Alpina')\n",
    "book['Genre'] = np.random.choice(\n",
    "    ['Action and Adventure', 'Classics', 'Comic Book', 'Detective', 'Mystery', 'Fantasy', 'Historical Fiction',\n",
    "     'Literary Fiction', 'Horror', 'Romance', 'Science Fiction', 'Short Stories', 'Suspense', 'Thrillers',\n",
    "     'Biographies', 'Autobiographies', 'Cookbooks', 'Essays', 'History', 'Memoir', 'Poetry', 'Self-Help', 'True Crime'],\n",
    "    len(book))\n",
    "book.ISBN = book.ISBN.fillna(random.randint(1000, 10000000))\n",
    "\n",
    "book.loc[book['PublishYear'] > 2023, 'PublishYear'] = random.randint(1900, 2023)\n",
    "book.loc[book['PublishMonth'] > 12, 'PublishMonth'] = random.randint(1, 12)\n",
    "book.loc[book['PublishDay'] > 31, 'PublishDay'] = random.randint(1, 31)\n",
    "book.loc[(book['Language'] == \"en-US\") | (book['Language'] == \"en-GB\") | (book['Language'] == \"en-CA\") | (\n",
    "        book['Language'] == \"--\"), 'Language'] = \"eng\"\n",
    "\n",
    "book = book[:1000]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# book.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Данные для таблиц\n",
    "- book\n",
    "- book_genre\n",
    "- book_lang\n",
    "- book_publisher\n",
    "- book_author"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "Book_genre = pd.DataFrame(data=book.Genre.unique(), columns=['Genre'])\n",
    "Book_lang = pd.DataFrame(data=book.Language.unique(), columns=['Language'])\n",
    "Book_publisher = pd.DataFrame(data=book.Publisher.unique(), columns=['Publisher'])\n",
    "Book_author = pd.DataFrame(data=book.Authors.unique(), columns=['Authors'])\n",
    "\n",
    "columns = [[Book_genre, \"Genre\"], [Book_lang, \"Language\"], [Book_publisher, \"Publisher\"], [Book_author, \"Authors\"]]\n",
    "for col in columns:\n",
    "    for index, string in enumerate(col[0].iloc[:, 0]):\n",
    "        book.loc[book[col[1]] == string, col[1]] = index + 1\n",
    "\n",
    "book.columns = ['book_title', 'book_page_num', 'book_publish_month', 'book_publish_day', 'book_publisher',\n",
    "                'book_num_reviews', 'book_publish_year', 'book_lang', 'book_author', 'book_rating', 'book_isbn',\n",
    "                'book_genre']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "outputs": [],
   "source": [
    "Book_genre.to_csv(\"output/book_genre.csv\", index=False)\n",
    "Book_lang.to_csv(\"output/book_lang.csv\", index=False)\n",
    "Book_publisher.to_csv(\"output/book_publisher.csv\", index=False)\n",
    "Book_author.to_csv(\"output/book_author.csv\", index=False)\n",
    "\n",
    "book.to_csv(\"output/book.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    port=\"5432\",\n",
    "    database=\"library\",\n",
    "    user='admin',\n",
    "    password='admin')\n",
    "\n",
    "cur = conn.cursor()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "address = pd.read_csv(\"input/address/open_pubs.csv\").drop([\"fas_id\", \"name\", \"local_authority\", \"easting\", \"northing\"], axis=1)\n",
    "\n",
    "# address = address[:1000]\n",
    "\n",
    "# address = address.values.tolist()\n",
    "# address_list = list()\n",
    "# for elem in address:\n",
    "#     address_list.append(f\"'{elem[0]}', '{elem[1]}', st_makepoint({elem[2]}, {elem[3]})\")\n",
    "#\n",
    "# cur.execute(f\"INSERT INTO address (address_name, address_postcode, address_geo) VALUES ({'), ('.join(address_list)});\")\n",
    "\n",
    "address.to_csv(\"output/address.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "conn.commit()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
